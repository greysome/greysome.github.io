The same introductory remarks as taocp-ch1-solutions.txt apply.





2.2.1-8 --------------------

If n>=5, then any permutation starting with n13... works. If n1 can be
output from the deque, that means right before n is output (when all n
elements are in the deque), either

1. n and 1 appear at both ends of the deque, or
2. n1.. in the left end or ..1n in the right end.

Thus the only possible arrangements are
123..n   n..321   n123..   ..321n,
and in each case 3 is stuck in the middle after n1 is output.





2.2.2-9 --------------------

Let xk be the stack of the kth insertion. The basic observation is
that the number of moves caused by this insertion is equal to the
number of previous insertion whose stack is > xk.

Let Xk be the random variable denoting the number of moves caused by
the kth insertion. We have

E(total moves)
= sum(1km) E(Xk)
= sum(1km) sum(1in) E(Xk|k=i) P(k=i)
= sum(1km) sum(1in) [(n-i)/n * (k-1)] 1/n
                     ^ expected number of values > i if sampled uniformly k times from 1 to n
= 1/n [sum(1km) (k-1)] [sum(1in) 1-i/n]
= 1/n (m 2) (n - 1/n * n(n+1)/2)
= 1/2 (1-1/n) (m 2).





2.2.2-10 --------------------

The method of 2.2.2-9 is easily adapted.





2.2.2-11 --------------------

Similar to 2.2.2-9,

E(total moves)
= sum(1km) E(Xk)
= sum(1km) sum(1in) E(Xk|k=i) P(k=i)
= sum(1km) sum(1in) sum(1lk) E(Xk|k=i, lth occurrence of i) P(lth occurrence of i) P(k=i)
                                                                                   ^ 1/n

We have

P(lth occurrence of i)
= P(l-1 occurrences of i in x1,...,x(k-1))
= (k-1 l-1) (n-1)^(k-l) / n^(k-1)

and

E(Xk|k=i, lth occurrence of i)
= (n-i)(k-t)/(n-1) if t>T, 0 otherwise.

Plugging these in, the inner most sum

sum(1lk) E(Xk|k=i, lth occurrence of i) P(lth occurrence of i)

evaluates to

0 if k=1,

(n-i)/n^(k-1) sum(t+1 l k) (k-1 l-1) (k-l) (n-1)^(k-l-1)
= (n-i)/n^(k-1) sum(t+1 l k) (k-2 l-1) (k-1) (n-1)^(k-2-(l-1))
= (n-i)(k-1)/n^(k-1) sum(t l k-1) (k-2 l) (n-1)^(k-2-l)
otherwise.

Denote the final sum by A(k-2); it represents the number of
(k-2)-tuples of {1,...,n} with >= t occurrences of a given number;
A1=0 as well. Apparently there is no simpler closed form.

Finally, the big sum evaluates to

1/n sum(1in) sum(2km) (n-i)(k-1)/n^(k-1) A(k-2)
= [sum(1in) (1-i/n)] [sum(2km) A(k-2) k-1 / n^(k-1)].
= (n-1)/2 [sum(2km) A(k-2) k-1 / n^(k-1)].

In the special case t=0, we have A(k-2)=n^(k-2), thus the expressionq
evaluates to

(n-1)/2 sum(2km) k-1 / n
= 1/2(1-1/n) sum(1 k m-1) k
= 1/2(1-1/n) (m 2),

which is the solution to 2.2.2-9.





2.2.2-12 --------------------

If n is even, the expectation is equal to 2^-n times

n/2 (n n/2) + 2 sum(0 k n/2-1) (n-k)(n k)
= n/2 (n n/2) + 2 sum(0 k n/2-1) n(n-1 k)   (recall (n n-k) = n/(n-k) (n-1 n-k-1))
= n/2 (n n/2) + 2n sum(0 k n/2-1) (n-1 k)   (sum over left half of (n-1)th row of Pascal's triangle)
= n/2 (n n/2) + 2^(n-1) n.
= n (n-1 n/2-1) + 2^(n-1) n.
= n (n-1 n/2) + 2^(n-1) n.

If n is odd, the expectation is equal to 2^-n times

2 sum(0 k (n-1)/2) (n-k) (n k)
= 2n sum(0 k (n-1)/2) (n-1 k)  (sum over left half of (n-1)th row, including middle term)
= 2n 1/2 [2^(n-1) + (n-1 (n-1)/2)]
= n 2^(n-1) + n (n-1 (n-1)/2)

In general, the answer is

n/2 + n 2^-n (n-1 floor(n/2)),

the difference from n/2 grows with n, since (n n/2) ~ sqrt(2) 2^n/sqrt(pi n).





2.2.2-16 --------------------

I was initially tempted to say yes: perhaps we could use the circular
queue idea. However, there are complications with the idea. Suppose at
some point, a certain amount of memory is allocated for the queue
(which implies an allocation of memory to the other structure, say a
stack). If the stack is full but the F and R pointers of the queue are
well off the end of the list, then we would be wasting a lot of space:

[  F...R               ][......................]

One might say, we could dynamically adjust the size of the queue so
that this doesn't happen. But that leads to more complications: if the
stack is always empty, do we let the queue grow to the right (thus
leaving less room for the stack to grow in the future), or do we force
it to wrap around at some point? Without an idea of the distribution
of insertions and deletions, it is hard to decide on an efficient
allocation scheme a priori.





2.2.2-18 --------------------

The idea is to spread out the cost of each expensive repacking
operation across the subsequent run of insertions and deletions. Let
bji denotes the fraction of memory used by stack i during the jth
repacking operation; thus if the repacking occurred on move k, then ak
= sum(i)bji. After the repacking, stack i is allowed to grow by

A(1-ak)N/n + (1-A)(1-ak)N * bji/ak    (where A=0.1 in Knuth's description of Algorithm R).

Therefore, the minimum number of moves to the next repacking is equal
to the minimum of these quantities, which is at least
A(1-ak)N/n. Thus, the cost of the jth repacking operation (which is C
ak N), is at most

C/A n sum(k l k'-1) al N / (1-al)N,

where the jth and (j+1)th repackings occur at moves k and k'. Summing
over all repackings, and taking into account the cost of each
insertion/deletion, we get the desired bound

O(m + n sum(1km) ai/(1-ai)).

(Pedantry: the repacking operation also includes costs from iterating
through the stacks to find which ones to move upward/downward, and
this contributes at most O(nm), which can be subsumed in the sum.)





2.2.3-21 --------------------

The situation is easy to visualise if we draw an arrow for each
relation j<k (repeated relations means multiple arrows connecting two
nodes): topological sort repeatedly removes nodes with no arrows
pointing to it.

Repeated relations are fine, they just take longer to process. However
if there is a loop, then every node has an arrow pointing to it and
the algorithm can't continue.





2.2.4-9 --------------------

A general observation: if P and Q point inside the same circular list,
then Algorithm A will behave as intended as long as P doesn't fall
behind Q:

- Each new term that is added, is added behind Q and thus behind P. So
  as we continuously advance P, it never "sees" the new terms and so
  they are never processed more than once.

- Addition of coefficients may happen at P, but we would advance P
  immediately anyway so we never read from the "dirty" node.

- Similarly, removal of zero terms works fine if P is *ahead* of Q by
  at least one node.

With these remarks, we can deduce:

P=Q in Algorithm A is ok. Note that no zero terms are created.

P=M in Algorithm M is ok because that list is never modified.


P=Q in Algorithm M results in t*poly(Q) getting added to poly(Q) for
each term t in poly(M), because each term in t*poly(Q) is >= some term
in poly(Q), thus each term is processed exactly once. Thus if
poly(M)=t1+...+tn then the effective result is the series of
assignments

poly(Q) <- poly(Q) + t1*poly(Q),
poly(Q) <- poly(Q) + t2*poly(Q),
...
poly(Q) <- poly(Q) + tn*poly(Q),

or equivalently

poly(Q) <- (1+t1)...(1+tn) poly(Q).


Q=M in Algorithm M is ok, because for each term t in poly(M), every
term of t*poly(P) is > t, so they all get added behind M. The
exception is when poly(P) contains a constant term, but the constant
term is already the last node in P, so we don't ever read from the
dirty node.





2.2.4-10,11 --------------------

My implementation below, which takes (24p+27)u where p is the number
of terms in poly(P). Not quite as good as Knuth's (21p+31)u but still
an improvement over (27p+13)u with Program A.

* Steps:
* 1. Set P1<-P, Q0<=AVAIL, COEF(Q0)<-COEF(P1), ABC(Q0)<-ABC(P1), Q<-Q0.
* 2. P1<-LINK(P1). If P1=sentinel, set LINK(Q)<-Q0 and terminate.
* 3. Set Q1<-Q, Q<=AVAIL, COEF(Q)<-COEF(P1), ABC(Q)<-ABC(P),
*    LINK(Q1)<-Q, and goto 2.
* Registers:
* rI2=Q0, rI3=Q, rI4=Q1, rI5=P1, rI6=tmp
COPY	STJ	9F		2
	ENT5	0,1		1	P1 <- P.
	LD2	AVAIL		2	Q0 <= AVAIL.
	J2Z	OVERFLOW	1
	LD6	1,2(LINK)	2
	ST6	AVAIL		2
	LDA	0,5		2	COEF(Q0) <- COEF(P1).
	STA	0,2		2
	LDA	1,5(ABC)	2	ABC(Q0) <- ABC(PQ).
	STA	1,2(ABC)	2
	ENT3	0,2		1	Q <- Q0.
2H	LD5	1,5(LINK)	2(p+1)	P1 <- LINK(P1).
	LDA	1,5(ABC)	2(p+1)
	JANN	3F		p+1	P1 = sentinel?
	ST2	1,3(LINK)	2	LINK(Q) <- Q0.
9H	JMP	*		1
3H	ENT4	0,3		p	Q1 <- Q.
	LD3	AVAIL		2p	Q <= AVAIL.
	J3Z	OVERFLOW	p
	LD6	1,3(LINK)	2p
	ST6	AVAIL		2p
	LDA	0,5		2p	COEF(Q) <- COEF(P1).
	STA	0,3		2p
	LDA	1,5(ABC)	2p	ABC(Q) <- ABC(P1).
	STA	1,3(ABC)	2p
	ST3	1,4(LINK)	2p	LINK(Q1) <- Q.
	JMP	2B		p





2.2.6-15 --------------------

In hindsight I made a poor choice of register assignments, because I
was left with no index registers to temporarily store PTR[J]. This
made S6 and S8 particularly awkward, as I had to resort to
self-modifying instruction shenanigans, e.g. storing PTR[J] into rX
and then storing rX into the next instruction's A-field which loads
ROW(PTR[J]).

If I were to rewrite this, I would store the row index I in memory
because it is rarely needed; thus freeing up rI1. (This was
essentially what Knuth did.)

* PIVOTSTEP
* Input: rI5=PIVOT. It is assumed that the BASECOL/BASEROW/PTR tables exist.
* Registers: rI1=I,X, rI2=J, rI3=P0, rI4=Q0, rI5=P1, rI6=P
ROW	EQU	0:3
UP	EQU	4:5
COL	EQU	0:3
LEFT	EQU	4:5
I0	CON	0
J0	CON	0
ALPHA	CON	0
PIVOTSTEP	STJ	9F
* rI5,rI6 are used as temp registers in the initialization step
S1 	LD6	0,5(ROW)	ROW(PIVOT)
	ST6	I0		  -> I0.
	LD3	BASEROW,6	P0 <- LOC(BASEROW[I0]).
	LD6	1,5(COL)	COL(PIVOT)
	ST6	J0		  -> J0.
	LD4	BASECOL,6	Q0 <- LOC(BASECOL[J0]).
	LDA	2,5		VAL(PIVOT)
	STA	ALPHA	  	  -> ALPHA.
	ENTA	=1.0=		1.0
	STA	2,5		  -> VAL(PIVOT).
S2	LD3	1,3(LEFT)	P0 <- LEFT(P0).
	LD2	1,3(COL)	J <- COL(P0).
	J2N	S3		J < 0?
	LDA	BASECOL,2	LOC(BASECOL[J])
	STA	PTR,2		  -> PTR[J].
	LDA	2,3		VAL(P0)
	FDIV	ALPHA	  	  / ALPHA
	STA	2,3		  -> VAL(P0).
	JMP	S2
S3	LD4	0,4(UP)		Q0 <- UP(Q0).
	LD1	0,4(ROW)	I <- ROW(Q0).
9H	J1N	*		I < 0? (then terminate)
	CMP1	I0		I = I0? (then repeat S3)
	JE	S3
	LD6	BASEROW,1	P <- LOC(BASEROW[I]).
	LD5	1,6(LEFT)	P1 <- LEFT(P).
S4	LD3	1,3(LEFT)	P0 <- LEFT(P0).
	LD2	1,3(COL)	J <- COL(P0).
	J2NN	1F		J < 0?
	LDAN	2,4		- VAL(Q0)
	FDIV	ALPHA	  	  / ALPHA
	STA	2,4		  -> VAL(Q0).
	JMP	S3
1H	CMP2	J0		J = J0? (then repeat S4)
	JE	S4
S5	LDA	1,5(COL)	Decrement COL(P1)
	DECA	0,2		  by J.
	JAZ	S7		If we matched pivot row's column, then pivot.
	JANP	S6		If we overshot, then insert.
	ENT6	0,5		Otherwise, we advance our column. P <- P1.
	LD5	1,6(LEFT)	P1 <- LEFT(P).
	JMP	S5
S6	LDX	PTR,2		rX <- PTR[J].
	STX	2F(0:2)
	STX	*+1(0:2)
	LDX	*(UP)		rX <- UP(PTR[J])
	STX	*+1(0:2)
	LDA	*(ROW)		rA <- ROW(UP(PTR[J])).
	DECA	0,1
	JANP	*+3		ROW(UP(PTR[J])) > I?
0H	STX	PTR,2		PTR[J] <- UP(PTR[J]).
	JMP	S6
	ST1	0F(0:2)		Temporary make rI1 point to new node X <= AVAIL.
	ST1	1F(0:2)
	LD1	AVAIL
	LDA	0,1(UP)		UP(AVAIL) points to the next node in the allocation list.
	STA	AVAIL
	ENTA	=0.0=		0.0
	STA	2,1		  -> VAL(X).
0H	ENTA	*
	STA	0,1(ROW)	ROW(X) <- I.
	ST2	1,1(COL)	COL(X) <- J.
	ST5	1,1(LEFT)	LEFT(X) <- P1.
	STX	0,1(UP)		UP(X) <- UP(PTR[J]).
	ST1	1,6(LEFT)	LEFT(P) <- X.
2H	ST1	*(UP)		UP(PTR[J]) <- X.
	ENT5	0,1		P1 <- X.
1H	ENT1	*		Restore I1.
S7	LDAN	2,3		- VAL(P0)
	FMUL	2,4		  * VAL(Q0)
	FADD	2,5		  + VAL(P1)
	STA	2,5		  -> VAL(P1).
	JAZ	S8		VAL(P1) = 0?
	ST5	PTR,2		PTR[J] <- P1.
	ENT6	0,5		P <- P1.
	LD5	1,6(LEFT)	P1 <- LEFT(P).
	JMP	S4
S8	LDA	PTR,2		rA <- PTR[J].
	STA	*+1(0:2)
	LDA	*(UP)		rA <- UP(PTR[J]).
	STA	0F(0:2)
	DECA	0,5		rA <- rA - P1.
	JAZ	*+4		UP(PTR[J]) = P1?
0H	ENTA	*		UP(PTR[J])
	STA	PTR,2		  -> PTR[J].
	JMP	S8
	LDX	0,5(UP)		UP(P1)
	LDA	PTR,2
	STA	*+1(0:2)
	STX	*(UP)		  -> UP(PTR[J]).
	LDA	1,5(LEFT)	LEFT(P1)
	STA	1,6(LEFT)	  -> LEFT(P).
	LDA	AVAIL
	STA	0,5(UP)
	ST5	AVAIL		AVAIL <= P1.
	LD5	1,6(LEFT)	P1 <- LEFT(P).
	JMP	S4





2.2.6-16 --------------------

The following algorithm copies the nodes of the original matrix and
populates the tables NEWROW and NEWCOL, which play the same role as
BASEROW and BASECOL. An auxiliary table PTR is also utilised. Suppose
the size of the matrix is M x N.

C1. [Initialize list heads]
    For 1<=I<=M, pop X<=AVAIL and set COL(X)<-(-1), NEWROW[I]<-X.
    For 1<=J<=N, pop X<=AVAIL and set ROW(X)<-(-1), NEWCOL[J]<-X, PTR[J]<-X.
    Set I=M.

C2. [Initialize row]
    Set P<-LEFT(BASEROW[I]), Y0<-NEWROW[I].

C3. [Check end of row]
    If P!=BASEROW[I], then go to step C4.
    Else, set LEFT[Y0]<-NEWROW[I]. If I=1 then go to C5, else
    decrement I and go back to C2.

C4. [Traverse row]
    Set X<-NODE(P), I<-ROW(X), J<-COL(X).
    Then pop Y<=AVAIL and set ROW(Y)<-I, COL(Y)<-J,
    LEFT(Y0)<-Y, Y0<-Y, UP(PTR[J])<-Y, PTR[J]<-Y.
    Go back to C3.

C5. [Update final UP links]
    For 1<=J<=N, set UP(PTR[J])<-NEWCOL[J]. Then terminate.





2.2.6-17 --------------------

The structure is quite similar to 2.2.6-16 in my use of Y0 and PTR.

The following algorithm multiples two matrices A, B with list heads
specified by AROW/ACOL and BROW/BCOL. It creates a new matrix C and
populates the newly created list heads in tables CROW/CCOL. An
auxiliary table PTR is also utilised. Suppose A is M x N and B is N x
K.

M1. [Initialize list heads]
    For 1<=I<=M, pop X<=AVAIL and set COL(X)<-(-1), CROW[I]<-X.
    For 1<=J<=K, pop X<=AVAIL and set ROW(X)<-(-1), CCOL[J]<-X, PTR[J]<-X.
    Set I=M.

M2. [Initialize row]
    If I<1, then skip to M8. Otherwise, set Y0<-NEWROW[I], J<-K.

M3. [Initialize column]
    If J<1, then skip to M7. Otherwise, set P<-LEFT(AROW[I]),
    Q<-UP(BCOL[J]), S<-0.

M4. [Find matching pair]
    If P=AROW[I], goto step M6.
    Otherwise, repeatedly set Q<-UP(Q) zero or more times until
    ROW(Q)<=COL(P).

M5. [Add to sum]
    If ROW(Q)=COL(P), set S<-S+VAL(P)*VAL(Q).
    In all cases, set P<-LEFT(P) and repeat M4.

M6. [Create new node]
    If S!=0, pop Y<=AVAIL and set ROW(Y)<-I, COL(Y)<-J,
    LEFT(Y0)<-Y, Y0<-Y, UP(PTR[J])<-Y, PTR[J]<-Y.
    In all cases, decrement J and go back to M3.

M7. [Update final LEFT link in row]
    Set LEFT(Y0)<-CROW[I], decrement I and go back to M2.

M8. [Update final UP links in columns]
    For 1<=J<=K, set UP(PTR[J])<-CCOL[J]. Then terminate.
